{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de24fb44-f309-4b05-833d-d9c98d441069",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Cairo University Faculty of Engineering\n",
    "## Machine Learning \n",
    "## Assignment 1 \n",
    "\n",
    "---\n",
    "\n",
    "Please write your full name here\n",
    "- **Name** : \"Andrew Mushen\"\n",
    "- **BN**   : 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21dd90e-5130-4c0f-8dd9-d13a5065db88",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning\n",
    "For this assignment, you will be using the Breast Cancer Wisconsin (Diagnostic) Database to create a classifier that can help diagnose patients. First, read through the description of the dataset (below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e651ae-cf60-4e23-aa51-4ca39dd77573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "cancer.keys()\n",
    "\n",
    "#print(cancer.DESCR) # Print the data set description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2351a51c-3694-43d8-92c6-7c236b1beb3e",
   "metadata": {},
   "source": [
    "The object returned by `load_breast_cancer()` is a scikit-learn Bunch object, which is similar to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe395f5a-c610-4171-be0a-bb31d8f5d452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()\n",
    "cancer.target_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1892678c-6743-4719-ac12-2c8775c35969",
   "metadata": {},
   "source": [
    "### Question 0\n",
    "\n",
    "How many features does the breast cancer dataset have?\n",
    "\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a2a53b-71b5-4f24-a7c5-9523a2f28cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_zero():\n",
    "    #return  len(cancer.feature_names)\n",
    "    return  len(cancer['feature_names'])\n",
    "    \n",
    "\n",
    "answer_zero()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a4289-dc2f-498a-8305-afe03ff24714",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Pandas dataframes are much easier and more interpretable when dealing with tables. **Convert the cancer data into dataframe.**\n",
    "\n",
    "Note: Scikit-learn works with lists, np arrays, scipy-sparse matrices, and pandas DataFrames, so converting the dataset to a DataFrame is not necessary for training any model.\n",
    "\n",
    "*This function should return a (569, 31) DataFrame with *\n",
    "\n",
    "*columns = *\n",
    "\n",
    "    ['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    "    'mean smoothness', 'mean compactness', 'mean concavity',\n",
    "    'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    "    'radius error', 'texture error', 'perimeter error', 'area error',\n",
    "    'smoothness error', 'compactness error', 'concavity error',\n",
    "    'concave points error', 'symmetry error', 'fractal dimension error',\n",
    "    'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    "    'worst smoothness', 'worst compactness', 'worst concavity',\n",
    "    'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
    "    'target']\n",
    "    \n",
    "*and index = *\n",
    "\n",
    "RangeIndex(start=0, stop=569, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233db5f6-d74f-42ee-b6c3-537447effcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "\n",
    "#1st methode using pandas    \n",
    "\n",
    "    cancerdf = pd.DataFrame(cancer['data'], columns=cancer['feature_names'] )\n",
    "    cancerdf['target'] = cancer['target']\n",
    "    return cancerdf\n",
    "    #return cancerdf.shape\n",
    "\n",
    "#2nd methode using numpy\n",
    "\n",
    "    #data = np.c_[cancer.data, cancer.target]\n",
    "    #columns = np.append(cancer.feature_names, [\"target\"])\n",
    "    #return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4add0a-d9d3-4052-bcf2-56b61c4bf53f",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "What is the class distribution? (i.e. how many instances of `malignant` and how many `benign`?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514559d7-5afe-4e40-aca8-c257dca18a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    cancerdf = answer_one()\n",
    "\n",
    "#1st methode (bugged inversed counted )\n",
    "\n",
    "    #unique_1, counts_1 = np.unique(cancer.target_names, return_inverse= True)\n",
    "    #unique_2, counts_2 = np.unique(cancer.target,return_counts= True )\n",
    "    #return dict(zip(unique_1,counts_1))\n",
    "\n",
    "#2st methode modifed on the first one \n",
    "\n",
    "    #unique, counted = np.unique(cancer.target_names, return_inverse= True)\n",
    "    #malignant = np.count_nonzero(cancer.target ==0)\n",
    "    #benign = np.count_nonzero(cancer.target ==1)\n",
    "    #count = [benign,malignant]\n",
    "    #return  dict(zip(unique,count))\n",
    "\n",
    "#3rd methode \n",
    "\n",
    "    counts = cancerdf.target.value_counts()\n",
    "    counts.index = \"benign malignant \".split()\n",
    "    return counts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8cc5ea-3c4b-45aa-98a3-255d5b2a1b77",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Split the DataFrame into `X` (the data) and `y` (the labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99dfb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    cancerdf= answer_one()\n",
    "    X= pd.DataFrame(cancer['data'], columns=cancer['feature_names'] )\n",
    "    #X = cancerdf[cancerdf.columns[:-1]]\n",
    "    y = cancerdf.target\n",
    "    return X,y\n",
    "    #return X.shape,y.shape\n",
    "    \n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3336f9-9517-4a9a-91ca-fba2bb25d6dc",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Using `train_test_split`, split `X` and `y` into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180b69e2-b4cb-488f-909e-79cee866fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def answer_four():\n",
    "    X, y = answer_three()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    #return X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "    \n",
    "\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb50095-8bec-4d75-9160-8338f9801dae",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Using KNeighborsClassifier, fit a k-nearest neighbors (knn) classifier with `X_train`, `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e5acd3-af98-4ab7-b309-40b319f9bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k_range = range(1,20)\n",
    "knn_score = [[],[]]\n",
    "def answer_five_modified():\n",
    "    for k in k_range:   \n",
    "            X_train, X_test, y_train, y_test = answer_four()\n",
    "            knn = KNeighborsClassifier(n_neighbors = k)\n",
    "            knn.fit(X_train, y_train)\n",
    "            knn_score.append([k,knn.score(X_test, y_test)])\n",
    "            \n",
    "        \n",
    "    #return np.amax(knn_score)\n",
    "    return knn_score\n",
    "\n",
    "answer_five_modified()\n",
    "\n",
    "\n",
    "\n",
    "#for this data when k increases the score increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "k_range = range(1,20)\n",
    "scores = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = answer_four()\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20]);\n",
    "print(np.amax(knn_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proportion = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "X, y = answer_three()\n",
    "\n",
    "plt.figure()\n",
    "score_with_S = [[],[]]\n",
    "for s in train_proportion:\n",
    "    scores = []\n",
    "    for i in range(1,100):\n",
    "        Xn_train, Xn_test, yn_train, yn_test = train_test_split(X, y, test_size = 1-s)\n",
    "        knn.fit(Xn_train, yn_train)\n",
    "        scores.append(knn.score(Xn_test, yn_test))   \n",
    "    plt.plot(s, np.mean(scores), 'bo')\n",
    "    score_with_S.append([np.mean(scores),s])\n",
    "\n",
    "print (np.max(score_with_S) )\n",
    "plt.xlabel('Training set proportion (%)')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#setting k to 1 \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    " \n",
    "def answer_five():\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    \n",
    "    return knn.fit(X_train, y_train)\n",
    "    \n",
    "answer_five()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dbd498-cb23-4cab-9138-c4b7e7db82c1",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Using your knn classifier, predict the class label using the median value for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d989ab-6fd5-440a-933f-b6c6ff1072b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_six():\n",
    "\n",
    "    cancerdf = answer_one()\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    mean = cancerdf.mean()[:-1].values.reshape(1,-1)\n",
    "    knn=answer_five()\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = answer_four()\n",
    "    #knn= KNeighborsClassifier(n_neighbors=1)\n",
    "    #knn.fit(X_train,y_train)\n",
    " \n",
    "    return knn.predict(mean)\n",
    "        \n",
    "answer_six()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07065db3-e464-473f-ab71-dbfeeee097f6",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Using your knn classifier, predict the class labels for the test set `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b7833-53ee-4a3d-8dea-ad654cf3d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_seven():\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "\n",
    "    knn = answer_five()\n",
    "    predictions = knn.predict(X_test)\n",
    "    #return predictions ,print(\"no cancer: {}\".format(len(predictions[predictions==0]))),print(\"cancer: {}\".format(len(predictions[predictions==1])))\n",
    "\n",
    "    return predictions , print(\"no cancer: {}\".format(np.count_nonzero(predictions ==0))), print(\" cancer: {}\".format(np.count_nonzero(predictions ==1)))\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42288a73-b635-402d-8c26-229dc49c79f8",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "Find the score (accuracy) of your knn classifier using `X_test` and `y_test` & `X_train` and `y_train`. \n",
    "- Is the training accuracy higher or lower that the testing accuracy? \n",
    "- According to the test accuracy, would this model generalize well to new inputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fa57dd-8326-4fe7-9110-4b5ba3d921fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_eight():\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    knn = answer_five()\n",
    "    return knn.score(X_test,y_test)\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d1ae2-967b-4df0-9bf0-2872b0c53535",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "##### Accuracy Plot\n",
    "* Create `mal_train_X`, `mal_train_y`,`ben_train_X`,`ben_train_y`, `mal_test_X`,`mal_test_y`, `ben_test_X` and `ben_test_y` portions of the dataset. Where `mal_train_X` contains all training samples that belongs to malignant class while `mal_train_y` contains all labels of the samples that belongs to malignant class, and so on for other variables.\n",
    "\n",
    "* Calculate Accuracy scores for each case and save all the results in a list called `scores` using knn model from question 5.\n",
    "\n",
    "Try using the plotting function below to visualize the differet predicition scores between training and test sets, as well as malignant and benign cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830729b6-9aa7-46c5-8cd1-04a3a7408f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def accuracy_plot():\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "\n",
    "    # Find the training and testing accuracies by target value (i.e. malignant, benign)\n",
    "    mal_train_X = X_train[y_train==0]\n",
    "    mal_train_y = y_train[y_train==0]\n",
    "    ben_train_X = X_train[y_train==1]\n",
    "    ben_train_y = y_train[y_train==1]\n",
    "\n",
    "    mal_test_X = X_test[y_test==0]\n",
    "    mal_test_y = y_test[y_test==0]\n",
    "    ben_test_X = X_test[y_test==1]\n",
    "    ben_test_y = y_test[y_test==1]\n",
    "\n",
    "    knn = answer_five()\n",
    "\n",
    "    scores = [  knn.score(mal_train_X, mal_train_y), \n",
    "                knn.score(ben_train_X, ben_train_y),\n",
    "                knn.score(mal_test_X, mal_test_y), \n",
    "                knn.score(ben_test_X, ben_test_y)]\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot the scores as a bar chart\n",
    "    bars = plt.bar(np.arange(4), scores, color=['#4c72b0','#4c72b0','#55a868','#55a868'])\n",
    "\n",
    "    # directly label the score onto the bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.gca().text(bar.get_x() + bar.get_width()/2, height*.90, '{0:.{1}f}'.format(height, 2),\n",
    "                     ha='center', color='w', fontsize=11)\n",
    "\n",
    "    # remove all the ticks (both axes), and tick labels on the Y axis\n",
    "    plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "    # remove the frame of the chart\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    plt.xticks([0,1,2,3], ['Malignant\\nTraining', 'Benign\\nTraining', 'Malignant\\nTest', 'Benign\\nTest'], alpha=0.8);\n",
    "    plt.title('Training and Test Accuracies for Malignant and Benign Cells', alpha=0.8)\n",
    "accuracy_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dda16d-0a7f-4376-a1e6-a82ca8b8e6eb",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "1. Load Iris dataset from sklearn.\n",
    "2. Split the data into training and testing (30% testing)\n",
    "3. Create scatter plot.\n",
    "4. From the scatter plot choose two features only to train a knn model with suitable \"k\" of your choice.\n",
    "5. Evaluate your model performance and comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23703d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "irisdf = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "irisdf['target'] = iris['target']\n",
    "X = irisdf[irisdf.columns[:-1]]\n",
    "y = irisdf.target\n",
    "training_size = 0.55\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=0, train_size=training_size)\n",
    "\n",
    "cmap = cm.get_cmap('gnuplot')\n",
    "iris = pd.plotting.scatter_matrix(X_train, c=y_train, marker='o', s=40, hist_kwds={\n",
    "                                  'bins': 15}, figsize=(10, 10), cmap=cmap)\n",
    "Iris_2_features = irisdf[[\"petal length (cm)\", \"petal width (cm)\"]]\n",
    "y = irisdf.target\n",
    "\n",
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Iris_2_features, y, random_state=0, train_size=training_size)\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks(range(1, 20))\n",
    "print(np.amax(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c9a92",
   "metadata": {},
   "source": [
    "data is scattered verywell in petal length and petal width \n",
    "\n",
    "which will give the best acc then data is trained "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec5e7fe",
   "metadata": {},
   "source": [
    "the training set size is what mainly controls the score of the knn - the value of \"K \" doesn't change it much\n",
    "\n",
    "the bigger the training set gets the more it goes to be overfitting \n",
    "\n",
    "so we alterate the training set size to accure the best reasonbale results\n",
    "\n",
    "the k values will be set to 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d19a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Iris_2_features = irisdf[[\"petal length (cm)\", \"petal width (cm)\"]]\n",
    "y = irisdf.target\n",
    "# change the paramters to control the preformance\n",
    "k = 4\n",
    "train_proportion = [0.3, 0.35, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]\n",
    "for s in train_proportion:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        Iris_2_features, y, random_state=0, train_size=s)\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    score = knn.score(X_test, y_test)\n",
    "    predictions = knn.predict(X_test)\n",
    "    predictions = pd.DataFrame(predictions).values.reshape(-1)\n",
    "    # print(y_test.shape)\n",
    "    # print(predictions.shape)\n",
    "    #size = predictions.size\n",
    "    checking = np.where(predictions == y_test, 'True', 'False')\n",
    "    # print(checking)\n",
    "    print(score)\n",
    "    print(\"mis-predicted: {}\".format(np.count_nonzero(checking == 'False')),\n",
    "          \", out of : {} \".format(y_test.size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4d3a63",
   "metadata": {},
   "source": [
    "the model still good at predicted even at low training set "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbc768028c3e6ead51d9a200ddcb2ec858ae62844dcd1994729a8279be9b48f2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
